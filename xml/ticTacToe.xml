<?xml version="1.0"?>

<!DOCTYPE simulator [
<!ATTLIST algorithm id ID #IMPLIED>
<!ATTLIST problem id ID #IMPLIED>
<!ATTLIST measurements id ID #IMPLIED>
]>

<simulator>
    <problems>
        <problem id="NeuralvsHandcoded" class="problem.coevolution.GameLearningOptimizationProblem" numberOfEvaluations="10">
            <game class="games.game.tictactoe.TicTacToe">
                <agent class="games.agent.state.StateEvaluationAgent">
                    <traversalStrategy class="games.agent.state.traversal.MinMaxAlphaBetaTraversalStrategy" MaxDepth="1">
                        <evaluator class="games.agent.state.evaluation.NeuralStateEvaluator">
                            <neuralNetwork class="nn.NeuralNetwork">
                                <architecture class="nn.architecture.Architecture">
                                    <architectureBuilder class="nn.architecture.builder.FeedForwardArchitectureBuilder">
                                        <addLayer class="nn.architecture.builder.LayerConfiguration"/> <!-- size is specified by neural input strategy-->
                                        <addLayer class="nn.architecture.builder.LayerConfiguration" size="2"/>
                                        <addLayer class="nn.architecture.builder.LayerConfiguration"/> <!-- size is specified by output interpretation strategy-->
                                        <layerBuilder class="nn.architecture.builder.PrototypeFullyConnectedLayerBuilder" domain="R(-1,1)" />
                                    </architectureBuilder>
                                </architecture>
                            </neuralNetwork>
                            <stateInputStrategy class="games.game.tictactoe.TTTStateInputStrategy"/>
                        </evaluator>
                    </traversalStrategy>
                </agent>
                <agent class="games.agent.state.StateEvaluationAgent">
                    <traversalStrategy class="games.agent.state.traversal.MinMaxAlphaBetaTraversalStrategy" MaxDepth="9">
                        <evaluator class="games.agent.state.evaluation.EndGameStateEvaluator"/>
                    </traversalStrategy>
                </agent>
                <scoringStrategy class="games.game.scoring.WinLoseDrawValueScoringStrategy" drawValue="1.0"/>
            </game>
        </problem>
        <problem id="NeuralvsRandom" class="problem.coevolution.GameLearningOptimizationProblem" numberOfEvaluations="30">
            <game class="games.game.tictactoe.TicTacToe">
                <agent class="games.agent.state.StateEvaluationAgent">
                    <traversalStrategy class="games.agent.state.traversal.MinMaxAlphaBetaTraversalStrategy" MaxDepth="1">
                        <evaluator class="games.agent.state.evaluation.NeuralStateEvaluator">
                            <neuralNetwork class="nn.NeuralNetwork">
                                <architecture class="nn.architecture.Architecture">
                                    <architectureBuilder class="nn.architecture.builder.FeedForwardArchitectureBuilder">
                                        <addLayer class="nn.architecture.builder.LayerConfiguration"/> <!-- size is specified by neural input strategy-->
                                        <addLayer class="nn.architecture.builder.LayerConfiguration" size="2"/>
                                        <addLayer class="nn.architecture.builder.LayerConfiguration"/> <!-- size is specified by output interpretation strategy-->
                                        <layerBuilder class="nn.architecture.builder.PrototypeFullyConnectedLayerBuilder" domain="R(-1,1)" />
                                    </architectureBuilder>
                                </architecture>
                            </neuralNetwork>
                            <stateInputStrategy class="games.game.tictactoe.TTTStateInputStrategy"/>
                        </evaluator>
                    </traversalStrategy>
                </agent>
                <agent class="games.agent.RandomAgent"/>
                <scoringStrategy class="games.game.scoring.WinLoseDrawValueScoringStrategy"/>
            </game>
        </problem>
    </problems>
    <algorithms>
        <algorithm id="lbest" class="pso.PSO">
            <addStoppingCondition class="stoppingcondition.MeasuredStoppingCondition"/>
            <initialisationStrategy class="algorithm.initialisation.ClonedPopulationInitialisationStrategy" entityNumber="20">
                <entityType class="pso.particle.StandardParticle">
                    <FitnessCalculator class = "util.calculator.PropertyBasedFitnessCalculator"/>
                </entityType>
            </initialisationStrategy>
        </algorithm>
    </algorithms>

    <measurements id="fitness" class="simulator.MeasurementSuite" resolution="1">
        <addMeasurement class="measurement.single.StoredFitness"/>
    </measurements>

    <simulations>
        <simulation samples="1">
            <algorithm idref="lbest"/>
            <problem idref="NeuralvsRandom"/>
            <measurements idref="fitness"/>
            <output format="TXT" file="data/TTTNvR.txt"/>
        </simulation>
        <simulation samples="1">
            <algorithm idref="lbest"/>
            <problem idref="NeuralvsHandcoded"/>
            <measurements idref="fitness" />
            <output format="TXT" file="data/TTTNvH.txt"/>
        </simulation>
    </simulations>
</simulator>
